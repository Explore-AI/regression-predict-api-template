{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Context\n",
    "\n",
    "Sendy, in partnership with insight2impact facility, is hosting a Zindi challenge to predict the estimated time of delivery of orders, from the point of driver pickup to the point of arrival at final destination.\n",
    "\n",
    "The solution will help Sendy enhance customer communication and improve the reliability of its service; which will ultimately improve customer experience. In addition, the solution will enable Sendy to realise cost savings, and ultimately reduce the cost of doing business, through improved resource management and planning for order scheduling.\n",
    "\n",
    "Sendy helps men and women behind every type of business to trade easily, deliver more competitively, and build extraordinary businesses.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Data is a critical component in helping Sendy to build more efficient, affordable and accessible solutions. Given the details of a Sendy order, can we use historic data to predict an accurate time for the arrival of the rider at the destination of a package? In this competition, we’re challenging you to build a model that predicts an accurate delivery time, from picking up a package to arriving at the final destination. An accurate arrival time prediction will help all businesses to improve their logistics and communicate an accurate time to their customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "train=pd.read_csv('Train.csv')\n",
    "rider=pd.read_csv('Riders.csv')\n",
    "train_set=train.merge(rider,how='left', on='Rider Id')\n",
    "Test=pd.read_csv('Test.csv')\n",
    "\n",
    "Test_final=Test.merge(rider,how='left', on='Rider Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Order No', 'User Id', 'Vehicle Type', 'Platform Type',\n",
       "       'Personal or Business', 'Placement - Day of Month',\n",
       "       'Placement - Weekday (Mo = 1)', 'Placement - Time',\n",
       "       'Confirmation - Day of Month', 'Confirmation - Weekday (Mo = 1)',\n",
       "       'Confirmation - Time', 'Arrival at Pickup - Day of Month',\n",
       "       'Arrival at Pickup - Weekday (Mo = 1)', 'Arrival at Pickup - Time',\n",
       "       'Pickup - Day of Month', 'Pickup - Weekday (Mo = 1)', 'Pickup - Time',\n",
       "       'Arrival at Destination - Day of Month',\n",
       "       'Arrival at Destination - Weekday (Mo = 1)',\n",
       "       'Arrival at Destination - Time', 'Distance (KM)', 'Temperature',\n",
       "       'Precipitation in millimeters', 'Pickup Lat', 'Pickup Long',\n",
       "       'Destination Lat', 'Destination Long', 'Rider Id',\n",
       "       'Time from Pickup to Arrival', 'No_Of_Orders', 'Age', 'Average_Rating',\n",
       "       'No_of_Ratings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21201 entries, 0 to 21200\n",
      "Data columns (total 32 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   Order No                                   21201 non-null  object \n",
      " 1   User Id                                    21201 non-null  object \n",
      " 2   Vehicle Type                               21201 non-null  object \n",
      " 3   Platform Type                              21201 non-null  int64  \n",
      " 4   Personal or Business                       21201 non-null  object \n",
      " 5   Placement - Day of Month                   21201 non-null  int64  \n",
      " 6   Placement - Weekday (Mo = 1)               21201 non-null  int64  \n",
      " 7   Placement - Time                           21201 non-null  object \n",
      " 8   Confirmation - Day of Month                21201 non-null  int64  \n",
      " 9   Confirmation - Weekday (Mo = 1)            21201 non-null  int64  \n",
      " 10  Confirmation - Time                        21201 non-null  object \n",
      " 11  Arrival at Pickup - Day of Month           21201 non-null  int64  \n",
      " 12  Arrival at Pickup - Weekday (Mo = 1)       21201 non-null  int64  \n",
      " 13  Arrival at Pickup - Time                   21201 non-null  object \n",
      " 14  Pickup - Day of Month                      21201 non-null  int64  \n",
      " 15  Pickup - Weekday (Mo = 1)                  21201 non-null  int64  \n",
      " 16  Pickup - Time                              21201 non-null  object \n",
      " 17  Arrival at Destination - Day of Month      21201 non-null  int64  \n",
      " 18  Arrival at Destination - Weekday (Mo = 1)  21201 non-null  int64  \n",
      " 19  Arrival at Destination - Time              21201 non-null  object \n",
      " 20  Distance (KM)                              21201 non-null  int64  \n",
      " 21  Temperature                                16835 non-null  float64\n",
      " 22  Precipitation in millimeters               552 non-null    float64\n",
      " 23  Pickup Lat                                 21201 non-null  float64\n",
      " 24  Pickup Long                                21201 non-null  float64\n",
      " 25  Destination Lat                            21201 non-null  float64\n",
      " 26  Destination Long                           21201 non-null  float64\n",
      " 27  Rider Id                                   21201 non-null  object \n",
      " 28  No_Of_Orders                               21201 non-null  int64  \n",
      " 29  Age                                        21201 non-null  int64  \n",
      " 30  Average_Rating                             21201 non-null  float64\n",
      " 31  No_of_Ratings                              21201 non-null  int64  \n",
      "dtypes: float64(7), int64(15), object(10)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Investigate and correctly format data structures \n",
    "X=train_set.drop('Time from Pickup to Arrival', axis=1)\n",
    "y=train_set['Time from Pickup to Arrival']\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique identifiers, Remove the columns.\n",
    "# Vehicle type is also removed since it does not vary\n",
    "X.drop(['Rider Id', 'Order No', 'User Id','Vehicle Type'], axis=1, inplace=True)\n",
    "Test_final.drop(['Rider Id', 'Order No', 'User Id','Vehicle Type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continous VariablesNo_Of_Orders                                  \n",
    "                                 \n",
    "* Age                                          \n",
    "* Average_Rating                               \n",
    "* No_of_Ratings \n",
    "* Distance (KM)     \n",
    "* Time from Pickup to Arrival\n",
    "* Precipitation\n",
    "\n",
    "# Intarval\n",
    "Temperature \n",
    "Placement - Day of Month                       \n",
    "Placement - Weekday (Mo = 1)                   \n",
    "Placement - Time                              \n",
    "Confirmation - Day of Month                    \n",
    "Confirmation - Weekday (Mo = 1)                \n",
    "Confirmation - Time                          \n",
    "Arrival at Pickup - Day of Month               \n",
    "Arrival at Pickup - Weekday (Mo = 1)           \n",
    "Arrival at Pickup - Time                      \n",
    "Pickup - Day of Month                          \n",
    "Pickup - Weekday (Mo = 1)                      \n",
    "Pickup - Time                                \n",
    "Arrival at Destination - Day of Month          \n",
    "Arrival at Destination - Weekday (Mo = 1)      \n",
    "Arrival at Destination - Time   \n",
    "\n",
    "\n",
    "# Catagorical \n",
    "* Customer type: Personal or Business  and\n",
    "* Platform Type\n",
    "* Pickup Lat                                 \n",
    "* Pickup Long                               \n",
    "* Destination Lat                            \n",
    "* Destination Long\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecoding Categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Platform Type', 'Personal or Business', 'Placement - Day of Month',\n",
       "       'Placement - Weekday (Mo = 1)', 'Placement - Time',\n",
       "       'Confirmation - Day of Month', 'Confirmation - Weekday (Mo = 1)',\n",
       "       'Confirmation - Time', 'Arrival at Pickup - Day of Month',\n",
       "       'Arrival at Pickup - Weekday (Mo = 1)', 'Arrival at Pickup - Time',\n",
       "       'Pickup - Day of Month', 'Pickup - Weekday (Mo = 1)', 'Pickup - Time',\n",
       "       'Distance (KM)', 'Temperature', 'Precipitation in millimeters',\n",
       "       'Pickup Lat', 'Pickup Long', 'Destination Lat', 'Destination Long',\n",
       "       'No_Of_Orders', 'Age', 'Average_Rating', 'No_of_Ratings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Destination Time, Days of the week and months of the day variables woll be dropped since,\n",
    "# They are not in the test dataset and should not impact travel time, since someone is already arrived destination\n",
    "X.drop(['Arrival at Destination - Day of Month','Arrival at Destination - Weekday (Mo = 1)','Arrival at Destination - Time'],\n",
    "        axis=1, inplace =True)\n",
    "X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\27784\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\27784\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\27784\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\27784\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\27784\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "X['Confirmation_Time']=np.nan\n",
    "for i in range(len(X['Confirmation - Time'])):\n",
    "    X['Confirmation_Time'][i]= str(X['Confirmation - Time'][i]).split(' ')[0]\n",
    "\n",
    "X['Placement_Time']=np.nan\n",
    "for i in range(len(X['Placement - Time'])):\n",
    "    X['Placement_Time'][i]= str(X['Placement - Time'][i]).split(' ')[0]\n",
    "\n",
    "X['Pickup_Time']=np.nan\n",
    "for i in range(len(X['Pickup - Time'])):\n",
    "    X['Pickup_Time'][i]= str(X['Pickup - Time'][i]).split(' ')[0]\n",
    "\n",
    "X['Arrival_at_Pickup_Time']=np.nan\n",
    "for i in range(len(X['Arrival at Pickup - Time'])):\n",
    "    X['Arrival_at_Pickup_Time'][i]= str(X['Arrival at Pickup - Time'][i]).split(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_num(df,col):\n",
    "    for i in range(len(df[col])):\n",
    "        hh, mm , ss = map(int, str(df[col][i]).split(':'))\n",
    "        df[col][i]=ss + 60*(mm + 60*hh)\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\27784\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: \"['10\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7cf71ec6704a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Placement_Time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Pickup_Time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Arrival_at_Pickup_Time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-894c089064d0>\u001b[0m in \u001b[0;36mtime_to_num\u001b[1;34m(df, col)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtime_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mhh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmm\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mhh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: \"['10\""
     ]
    }
   ],
   "source": [
    "X1=time_to_num(X,'Confirmation_Time')\n",
    "X2=time_to_num(X1,'Placement_Time')\n",
    "X3=time_to_num(X2,'Pickup_Time')\n",
    "X=time_to_num(X3,'Arrival_at_Pickup_Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform Type</th>\n",
       "      <th>Personal or Business</th>\n",
       "      <th>Placement - Day of Month</th>\n",
       "      <th>Placement - Weekday (Mo = 1)</th>\n",
       "      <th>Placement - Time</th>\n",
       "      <th>Confirmation - Day of Month</th>\n",
       "      <th>Confirmation - Weekday (Mo = 1)</th>\n",
       "      <th>Confirmation - Time</th>\n",
       "      <th>Arrival at Pickup - Day of Month</th>\n",
       "      <th>Arrival at Pickup - Weekday (Mo = 1)</th>\n",
       "      <th>...</th>\n",
       "      <th>Destination Lat</th>\n",
       "      <th>Destination Long</th>\n",
       "      <th>No_Of_Orders</th>\n",
       "      <th>Age</th>\n",
       "      <th>Average_Rating</th>\n",
       "      <th>No_of_Ratings</th>\n",
       "      <th>Confirmation_Time</th>\n",
       "      <th>Placement_Time</th>\n",
       "      <th>Pickup_Time</th>\n",
       "      <th>Arrival_at_Pickup_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9:35:46 AM</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9:40:10 AM</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.300406</td>\n",
       "      <td>36.829741</td>\n",
       "      <td>1637</td>\n",
       "      <td>1309</td>\n",
       "      <td>13.8</td>\n",
       "      <td>549</td>\n",
       "      <td>34810</td>\n",
       "      <td>34546</td>\n",
       "      <td>37650</td>\n",
       "      <td>[10:04:47, AM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Personal</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>11:16:16 AM</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>11:23:21 AM</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.295004</td>\n",
       "      <td>36.814358</td>\n",
       "      <td>396</td>\n",
       "      <td>339</td>\n",
       "      <td>13.6</td>\n",
       "      <td>69</td>\n",
       "      <td>41001</td>\n",
       "      <td>40576</td>\n",
       "      <td>42249</td>\n",
       "      <td>[11:40:22, AM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>12:39:25 PM</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>12:42:44 PM</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.300921</td>\n",
       "      <td>36.828195</td>\n",
       "      <td>1023</td>\n",
       "      <td>242</td>\n",
       "      <td>12.5</td>\n",
       "      <td>114</td>\n",
       "      <td>45764</td>\n",
       "      <td>45565</td>\n",
       "      <td>46383</td>\n",
       "      <td>[12:49:34, PM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>9:25:34 AM</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>9:26:05 AM</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.257147</td>\n",
       "      <td>36.795063</td>\n",
       "      <td>886</td>\n",
       "      <td>283</td>\n",
       "      <td>14.5</td>\n",
       "      <td>113</td>\n",
       "      <td>33965</td>\n",
       "      <td>33934</td>\n",
       "      <td>34986</td>\n",
       "      <td>[9:37:56, AM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Personal</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9:55:18 AM</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9:56:18 AM</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.295041</td>\n",
       "      <td>36.809817</td>\n",
       "      <td>2311</td>\n",
       "      <td>872</td>\n",
       "      <td>14.1</td>\n",
       "      <td>533</td>\n",
       "      <td>35778</td>\n",
       "      <td>35718</td>\n",
       "      <td>36323</td>\n",
       "      <td>[10:03:53, AM]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Platform Type Personal or Business  Placement - Day of Month  \\\n",
       "0              3             Business                         9   \n",
       "1              3             Personal                        12   \n",
       "2              3             Business                        30   \n",
       "3              3             Business                        15   \n",
       "4              1             Personal                        13   \n",
       "\n",
       "   Placement - Weekday (Mo = 1) Placement - Time  Confirmation - Day of Month  \\\n",
       "0                             5       9:35:46 AM                            9   \n",
       "1                             5      11:16:16 AM                           12   \n",
       "2                             2      12:39:25 PM                           30   \n",
       "3                             5       9:25:34 AM                           15   \n",
       "4                             1       9:55:18 AM                           13   \n",
       "\n",
       "   Confirmation - Weekday (Mo = 1) Confirmation - Time  \\\n",
       "0                                5          9:40:10 AM   \n",
       "1                                5         11:23:21 AM   \n",
       "2                                2         12:42:44 PM   \n",
       "3                                5          9:26:05 AM   \n",
       "4                                1          9:56:18 AM   \n",
       "\n",
       "   Arrival at Pickup - Day of Month  Arrival at Pickup - Weekday (Mo = 1)  \\\n",
       "0                                 9                                     5   \n",
       "1                                12                                     5   \n",
       "2                                30                                     2   \n",
       "3                                15                                     5   \n",
       "4                                13                                     1   \n",
       "\n",
       "   ... Destination Lat  Destination Long  No_Of_Orders   Age  Average_Rating  \\\n",
       "0  ...       -1.300406         36.829741          1637  1309            13.8   \n",
       "1  ...       -1.295004         36.814358           396   339            13.6   \n",
       "2  ...       -1.300921         36.828195          1023   242            12.5   \n",
       "3  ...       -1.257147         36.795063           886   283            14.5   \n",
       "4  ...       -1.295041         36.809817          2311   872            14.1   \n",
       "\n",
       "   No_of_Ratings  Confirmation_Time  Placement_Time  Pickup_Time  \\\n",
       "0            549              34810           34546        37650   \n",
       "1             69              41001           40576        42249   \n",
       "2            114              45764           45565        46383   \n",
       "3            113              33965           33934        34986   \n",
       "4            533              35778           35718        36323   \n",
       "\n",
       "   Arrival_at_Pickup_Time  \n",
       "0          [10:04:47, AM]  \n",
       "1          [11:40:22, AM]  \n",
       "2          [12:49:34, PM]  \n",
       "3           [9:37:56, AM]  \n",
       "4          [10:03:53, AM]  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for i in range(len(X['Pickup - Time'])):\n",
    "        X['Arrival_at_Pickup_Time']=datetime.strptime(str(X['Arrival_at_Pickup_Time'][i]), '%H:%M:%S').time()\n",
    "        X['Pickup_Time']=datetime.strptime(str(X['Pickup_Time'][i]), '%H:%M:%S').time()\n",
    "        X['Confirmation_Time']=datetime.strptime(str(X['Confirmation_Time'][i]), '%H:%M:%S').time()\n",
    "        X['Placement_Time']=datetime.strptime(str(X['Placement_Time'][i]), '%H:%M:%S').time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['Pickup - Time','Placement - Time','Confirmation - Time', 'Arrival at Pickup - Time'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer type ( personal or business)\n",
    "X['Platform Type']=X['Platform Type'].astype('object')\n",
    "\n",
    "#Time\n",
    "#X['Placement - Time(AM/PM)'] = ['AM' if 'AM' in x else 'PM' for x in X['Placement - Time']]\n",
    "#X['Confirmation - Time(AM/PM)'] = ['AM' if 'AM' in x else 'PM' for x in X['Confirmation - Time']]\n",
    "#X['Arrival At Pickup - Time(AM/PM)'] = ['AM' if 'AM' in x else 'PM' for x in X['Arrival at Pickup - Time']]\n",
    "#X['Pickup - Time(AM/PM)'] = ['AM' if 'AM' in x else 'PM' for x in X['Pickup - Time']]\n",
    "\n",
    "# Weekdays are also converted intto catergories, so that the impact of each day on travel time can be compared with other days.\n",
    "X['Placement - Weekday (Mo = 1)']= X['Placement - Weekday (Mo = 1)'].astype('object')\n",
    "X['Confirmation - Weekday (Mo = 1)']=X['Confirmation - Weekday (Mo = 1)'].astype('object')\n",
    "X['Arrival at Pickup - Weekday (Mo = 1)']=X['Arrival at Pickup - Weekday (Mo = 1)'].astype('object')\n",
    "X['Pickup - Weekday (Mo = 1)']=X['Pickup - Weekday (Mo = 1)'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original time variable since, since catergorical variables for time are created\n",
    "# Comparison will be done for afternoon and before noon (AM and PM)\n",
    "#X.drop(['Placement - Time','Arrival at Pickup - Time','Confirmation - Time','Pickup - Time'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dummy variables from all the categorical variables in the dataset\n",
    "X_dummies = pd.get_dummies(X,columns=['Placement - Weekday (Mo = 1)','Confirmation - Weekday (Mo = 1)',\n",
    "                                     'Arrival at Pickup - Weekday (Mo = 1)','Pickup - Weekday (Mo = 1)',\n",
    "                                     'Platform Type','Personal or Business'], drop_first=True)\n",
    "len(X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Placement - Day of Month', 'Confirmation - Day of Month',\n",
       "       'Arrival at Pickup - Day of Month', 'Pickup - Day of Month',\n",
       "       'Distance (KM)', 'Temperature', 'Precipitation in millimeters',\n",
       "       'Pickup Lat', 'Pickup Long', 'Destination Lat', 'Destination Long',\n",
       "       'No_Of_Orders', 'Age', 'Average_Rating', 'No_of_Ratings',\n",
       "       'Confirmation_Time', 'Placement_Time', 'Pickup_Time',\n",
       "       'Arrival_at_Pickup_Time', 'Placement - Weekday (Mo = 1)_2',\n",
       "       'Placement - Weekday (Mo = 1)_3', 'Placement - Weekday (Mo = 1)_4',\n",
       "       'Placement - Weekday (Mo = 1)_5', 'Placement - Weekday (Mo = 1)_6',\n",
       "       'Placement - Weekday (Mo = 1)_7', 'Confirmation - Weekday (Mo = 1)_2',\n",
       "       'Confirmation - Weekday (Mo = 1)_3',\n",
       "       'Confirmation - Weekday (Mo = 1)_4',\n",
       "       'Confirmation - Weekday (Mo = 1)_5',\n",
       "       'Confirmation - Weekday (Mo = 1)_6',\n",
       "       'Confirmation - Weekday (Mo = 1)_7',\n",
       "       'Arrival at Pickup - Weekday (Mo = 1)_2',\n",
       "       'Arrival at Pickup - Weekday (Mo = 1)_3',\n",
       "       'Arrival at Pickup - Weekday (Mo = 1)_4',\n",
       "       'Arrival at Pickup - Weekday (Mo = 1)_5',\n",
       "       'Arrival at Pickup - Weekday (Mo = 1)_6',\n",
       "       'Arrival at Pickup - Weekday (Mo = 1)_7', 'Pickup - Weekday (Mo = 1)_2',\n",
       "       'Pickup - Weekday (Mo = 1)_3', 'Pickup - Weekday (Mo = 1)_4',\n",
       "       'Pickup - Weekday (Mo = 1)_5', 'Pickup - Weekday (Mo = 1)_6',\n",
       "       'Pickup - Weekday (Mo = 1)_7', 'Platform Type_2', 'Platform Type_3',\n",
       "       'Platform Type_4', 'Personal or Business_Personal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dummies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinates:\n",
    "Longitudes and Latitudes were used to calculate the distance between the two geographical points\n",
    "The distance calculated is perfectly correlated with the Distance in the data, so thefore Longitude and Latitude variables\n",
    " with the calculated distance, only the original distance is kept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    r = 6371\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2-lat1)\n",
    "    delta_lambda = np.radians(lon2-lon1)\n",
    "    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) *   np.sin(delta_lambda / 2)**2\n",
    "    res = r * (2 * np.arctan2(np.sqrt(a), np.sqrt(1-a)))\n",
    "    return np.round(res, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dist_calc (KM)</th>\n",
       "      <th>Distance (KM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.34</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.88</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.94</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.72</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dist_calc (KM)  Distance (KM)\n",
       "0            1.93              4\n",
       "1           11.34             16\n",
       "2            1.88              3\n",
       "3            4.94              9\n",
       "4            3.72              9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dummies['Dist_calc (KM)']=haversine_distance(X_dummies['Pickup Lat'], X_dummies['Pickup Long'], X_dummies['Destination Lat'], X_dummies['Destination Long'])\n",
    "X_dummies[['Dist_calc (KM)', 'Distance (KM)']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x18d28995ac8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter('Distance (KM)', 'Dist_calc (KM)', data= X_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies.drop(['Dist_calc (KM)'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# investigate missing values and treat them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:16835\n",
      "Precipitation in millimeters:552\n"
     ]
    }
   ],
   "source": [
    "for col in X_dummies.columns:\n",
    "    if X_dummies[col].count() <len(X_dummies[col]):\n",
    "        print(col + ':' + str(X_dummies[col].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precipitation is missing:97.39634922880997observations\n",
      "Temperature is missing only:20.5933682373473observations\n"
     ]
    }
   ],
   "source": [
    "# The dataset have a total of 21201 observations\n",
    "print('Precipitation is missing' + ':' + str((1-(552/21201))*100) + 'observations')\n",
    "print('Temperature is missing only' + ':' + str((1-(16835/21201))*100) + 'observations')\n",
    "\n",
    "# Missing values for temperature will be imputed, while precipitation will be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Precipitation\n",
    "X_dummies.drop('Precipitation in millimeters', axis=1, inplace=True)\n",
    "\n",
    "# Imputing missing values for temperature with the average temperature\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X_dummies['Temperature'].values.reshape(len(X_dummies['Temperature']),1))\n",
    "X_dummies['Temperature']= imputer.transform(X_dummies['Temperature'].values.reshape(len(X_dummies['Temperature']),1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21201 entries, 0 to 21200\n",
      "Data columns (total 46 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Placement - Day of Month                21201 non-null  int64  \n",
      " 1   Confirmation - Day of Month             21201 non-null  int64  \n",
      " 2   Arrival at Pickup - Day of Month        21201 non-null  int64  \n",
      " 3   Pickup - Day of Month                   21201 non-null  int64  \n",
      " 4   Distance (KM)                           21201 non-null  int64  \n",
      " 5   Temperature                             21201 non-null  float64\n",
      " 6   Pickup Lat                              21201 non-null  float64\n",
      " 7   Pickup Long                             21201 non-null  float64\n",
      " 8   Destination Lat                         21201 non-null  float64\n",
      " 9   Destination Long                        21201 non-null  float64\n",
      " 10  No_Of_Orders                            21201 non-null  int64  \n",
      " 11  Age                                     21201 non-null  int64  \n",
      " 12  Average_Rating                          21201 non-null  float64\n",
      " 13  No_of_Ratings                           21201 non-null  int64  \n",
      " 14  Confirmation_Time                       21201 non-null  object \n",
      " 15  Placement_Time                          21201 non-null  object \n",
      " 16  Pickup_Time                             21201 non-null  object \n",
      " 17  Arrival_at_Pickup_Time                  21201 non-null  object \n",
      " 18  Placement - Weekday (Mo = 1)_2          21201 non-null  uint8  \n",
      " 19  Placement - Weekday (Mo = 1)_3          21201 non-null  uint8  \n",
      " 20  Placement - Weekday (Mo = 1)_4          21201 non-null  uint8  \n",
      " 21  Placement - Weekday (Mo = 1)_5          21201 non-null  uint8  \n",
      " 22  Placement - Weekday (Mo = 1)_6          21201 non-null  uint8  \n",
      " 23  Placement - Weekday (Mo = 1)_7          21201 non-null  uint8  \n",
      " 24  Confirmation - Weekday (Mo = 1)_2       21201 non-null  uint8  \n",
      " 25  Confirmation - Weekday (Mo = 1)_3       21201 non-null  uint8  \n",
      " 26  Confirmation - Weekday (Mo = 1)_4       21201 non-null  uint8  \n",
      " 27  Confirmation - Weekday (Mo = 1)_5       21201 non-null  uint8  \n",
      " 28  Confirmation - Weekday (Mo = 1)_6       21201 non-null  uint8  \n",
      " 29  Confirmation - Weekday (Mo = 1)_7       21201 non-null  uint8  \n",
      " 30  Arrival at Pickup - Weekday (Mo = 1)_2  21201 non-null  uint8  \n",
      " 31  Arrival at Pickup - Weekday (Mo = 1)_3  21201 non-null  uint8  \n",
      " 32  Arrival at Pickup - Weekday (Mo = 1)_4  21201 non-null  uint8  \n",
      " 33  Arrival at Pickup - Weekday (Mo = 1)_5  21201 non-null  uint8  \n",
      " 34  Arrival at Pickup - Weekday (Mo = 1)_6  21201 non-null  uint8  \n",
      " 35  Arrival at Pickup - Weekday (Mo = 1)_7  21201 non-null  uint8  \n",
      " 36  Pickup - Weekday (Mo = 1)_2             21201 non-null  uint8  \n",
      " 37  Pickup - Weekday (Mo = 1)_3             21201 non-null  uint8  \n",
      " 38  Pickup - Weekday (Mo = 1)_4             21201 non-null  uint8  \n",
      " 39  Pickup - Weekday (Mo = 1)_5             21201 non-null  uint8  \n",
      " 40  Pickup - Weekday (Mo = 1)_6             21201 non-null  uint8  \n",
      " 41  Pickup - Weekday (Mo = 1)_7             21201 non-null  uint8  \n",
      " 42  Platform Type_2                         21201 non-null  uint8  \n",
      " 43  Platform Type_3                         21201 non-null  uint8  \n",
      " 44  Platform Type_4                         21201 non-null  uint8  \n",
      " 45  Personal or Business_Personal           21201 non-null  uint8  \n",
      "dtypes: float64(6), int64(8), object(4), uint8(28)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "X_dummies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 745],\n",
       "       [1993],\n",
       "       [ 455],\n",
       "       ...,\n",
       "       [2953],\n",
       "       [1380],\n",
       "       [2128]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(y)\n",
    "y=y.reshape(len(y),1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ae27c0418eeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 506\u001b[1;33m                                    y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    804\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# fit Linear model\n",
    "#Splitting the data into training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(X_dummies,y, test_size=0.2,random_state=40)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm=LinearRegression()\n",
    "lm.fit(x_train, y_train)\n",
    "y_pred=lm.predict(x_test)\n",
    "\n",
    "#Model Perfomance Validation\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print( 'Rsquared :'  + str(r2_score(y_test, y_pred)))\n",
    "print('RMSE :' + str(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
    "# Aim at having a RMSE of less than 780\n",
    "\n",
    "#and cross validate perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the features and target variable for data visualisation\n",
    "df=X_dummies.copy()\n",
    "df['Time from Pickup to Arrival']=y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot histograms for numeric features - lookout for outliers and leverage points\n",
    "#train_set['Time from Pickup to Arrival'].hist(bins=50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "sns.distplot(train_set['Time from Pickup to Arrival'], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time from Pickup to Arrival'].describe()\n",
    "# The median value is 1369 seconds while the mean is 1559.9, the data has very large influencial values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time from Pickup to Arrival is skewed to the right\n",
    "There is also a second pick close to zero seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "sns.boxplot(x='Time from Pickup to Arrival', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot above shows the posibility of outliers, there are very large numbers in our travel time variable\n",
    "# The box plot uses inter-quartile range to detect outliers. Here, we first determine the quartiles Q1 and Q3.\n",
    "\n",
    "#Interquartile range is given by (IQR) = Q3 — Q1\n",
    "Q3= 2040\n",
    "Q1= 882\n",
    "IQR = Q3-Q1\n",
    "\n",
    "Upperlimit = Q3+1.5* IQR\n",
    "\n",
    "Lowerlimit = Q1-(1.5*IQR)\n",
    "print(Upperlimit)\n",
    "print(Lowerlimit)\n",
    "\n",
    "#All the data is above the lower limit, however there are points that far exceeds the upper limit of 3777 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot histograms for categorical features - Lookout for too many levels that can be grouped together\n",
    "#df['Pickup - Day of Month'].hist(bins=100)\n",
    "#df['Placement - Day of Month  '].hist(bins=100\n",
    "#df['Arrival at Pickup - Day of Month'].hist(bins=100\n",
    "df['Confirmation - Day of Month'].hist(bins=100)                                \n",
    "                                 \n",
    "                                 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_months(df,col):\n",
    "    df['Weeks_Month_Cat']=np.nan\n",
    "    for i in range(len(df[col])):\n",
    "        if df[col][i]<=7:\n",
    "            df['Weeks_Month_Cat'][i]='first week'\n",
    "        elif df[col][i]<=14:\n",
    "            df['Weeks_Month_Cat'][i]='second week'\n",
    "        elif df[col][i]<=21:\n",
    "            df['Weeks_Month_Cat'][i]='third week'\n",
    "        else:\n",
    "            df['Weeks_Month_Cat'][i]='last wee'\n",
    "    return df['Weeks_Month_Cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Confirmation_Month_Cat']=change_months(df,'Confirmation - Day of Month')\n",
    "df['Placement_Month_Cat']=change_months(df,'Placement - Day of Month')\n",
    "df['Arrival_at_Pick_up_Month_Cat']=change_months(df,'Arrival at Pickup - Day of Month')\n",
    "df['Pickup_Month_Cat']=change_months(df,'Pickup - Day of Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Confirmation - Day of Month','Placement - Day of Month','Arrival at Pickup - Day of Month','Pickup - Day of Month'],axis=1,\n",
    "        inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# analyse relationships between features (correlation and factor analysis)\n",
    "g=sns.pairplot(df[['No_Of_Orders', 'Age', 'Average_Rating','Distance (KM)','Temperature','No_of_Ratings','Time from Pickup to Arrival']])\n",
    "g.fig.set_size_inches(9,9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check for collinearity and multi-collinearity\n",
    "\n",
    "corr = df.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(7, 5))\n",
    "    ax = sns.heatmap(corr, mask=mask, square=True,cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.correlation import plot_corr\n",
    "\n",
    "fig = plt.figure(figsize=(15,15));\n",
    "ax = fig.add_subplot(111);\n",
    "plot_corr(df.corr(), xnames = df.corr().columns, ax = ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All weekday variables(Pick up, confirmmation, etc) are correlated, will remove all other 3 variables, \n",
    "#Times are also highly correlated, only one variable will be left.\n",
    "#Also days of the months variables\n",
    "\n",
    "X_dummies.drop([ 'Placement - Day of Month', 'Confirmation - Day of Month','Arrival at Pickup - Day of Month','Confirmation - Weekday (Mo = 1)_2',\n",
    "       'Confirmation - Weekday (Mo = 1)_3','Confirmation - Weekday (Mo = 1)_4','Confirmation - Weekday (Mo = 1)_5','Confirmation - Weekday (Mo = 1)_6',\n",
    "       'Confirmation - Weekday (Mo = 1)_7','Arrival at Pickup - Weekday (Mo = 1)_2','Arrival at Pickup - Weekday (Mo = 1)_3','Arrival at Pickup - Weekday (Mo = 1)_4',\n",
    "       'Arrival at Pickup - Weekday (Mo = 1)_5','Arrival at Pickup - Weekday (Mo = 1)_6','Arrival at Pickup - Weekday (Mo = 1)_7',  'Placement - Weekday (Mo = 1)_2', \n",
    "       'Placement - Weekday (Mo = 1)_3','Placement - Weekday (Mo = 1)_4', 'Placement - Weekday (Mo = 1)_5',\n",
    "       'Placement - Weekday (Mo = 1)_6', 'Placement - Weekday (Mo = 1)_7','Arrival At Pickup - Time(AM/PM)_PM',\n",
    "        'Placement - Time(AM/PM)_PM',\n",
    "       'Confirmation - Time(AM/PM)_PM'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# analyses relationship between features and target\n",
    "plt.figure\n",
    "\n",
    "plt.scatter(df['Distance (KM)'],'Time from Pickup to Arrival', data=df)\n",
    "\n",
    "#sns.regplot((df['Distance (KM)']),'Time from Pickup to Arrival', data=df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure    \n",
    "sns.jointplot('Temperature','Time from Pickup to Arrival', data=train_set)\n",
    "sns.jointplot(np.log(train_set['Temperature']),'Time from Pickup to Arrival', data=train_set,)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train_set, row='Platform Type', col='Personal or Business', height=2.0, aspect=3.0)\n",
    "grid.map(plt.hist,'Time from Pickup to Arrival', bins=30)\n",
    "grid.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.groupby('Platform Type').count()['Time from Pickup to Arrival']\n",
    "# Platform type 3 accounts for over 80% of the sample, while platform type 4 for acounts for approx 0.0% (20) of the total sample\n",
    "# Platform type 3 will be compared to the rest of the platfofms\n",
    "# Also from the above graph it seems like business customers use platform 3 the most, while personal customers use the other platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train_set, row='Pickup - Weekday (Mo = 1)', col='Personal or Business', height=2.0, aspect=3.0)\n",
    "grid.map(plt.hist,'Time from Pickup to Arrival', bins=30)\n",
    "grid.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train_set, row='Pickup - Weekday (Mo = 1)', col='Personal or Business', height=2.0, aspect=3.0)\n",
    "grid.map(plt.hist,'Time from Pickup to Arrival', bins=30)\n",
    "grid.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.jointplot('Average_Rating','No_of_Ratings', data=train_set)\n",
    "\n",
    "#sns.jointplot('Average_Rating','Time from Pickup to Arrival', data=train_set)\n",
    "sns.regplot('No_of_Ratings','Time from Pickup to Arrival', data=train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.jointplot('Average_Rating','Time from Pickup to Arrival', data=train_set)\n",
    "sns.jointplot('Age','Time from Pickup to Arrival', data=train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benchmach model** After removing the highly correlated variables exposed by the visuals above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit Linear model\n",
    "#Splitting the data into training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(X_dummies,y, test_size=0.2,random_state=40)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm=LinearRegression()\n",
    "lm.fit(x_train, y_train)\n",
    "y_pred=lm.predict(x_test)\n",
    "\n",
    "#Model Perfomance Validation\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print( 'Rsquared :'  + str(r2_score(y_test, y_pred)))\n",
    "lm_test=np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "lm_train=np.sqrt(mean_squared_error(y_train, lm.predict(x_train)))\n",
    "print('RMSE :' + str(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
    "# Aim at having a RMSE of less than 780\n",
    "# RMSE increased from 790 to 791 and R2 decreased from 35.5% to 35.37%\n",
    "# These are small changes, therefore the variavbles removed had very litte explanatory power while causing multicolinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# investigate non linearity\n",
    "X_nonlnr=X_dummies.copy()\n",
    "\n",
    "#Temperature is transformed using log, as it seems to be non linear with y\n",
    "X_nonlnr['log_tempreture']=np.log(X_nonlnr['Temperature'])\n",
    "\n",
    "#Transforming platform type to two catergories as mentioned\n",
    "X_nonlnr['Platform_type']=X['Platform Type']\n",
    "\n",
    "X_nonlnr['Platform_type_3_other(0)']=np.nan\n",
    "for i in range(len(X_nonlnr['Platform_type'])):\n",
    "    if X_nonlnr['Platform_type'][i]==3:\n",
    "          X_nonlnr['Platform_type_3_other(0)'][i]=int(1)\n",
    "    else:\n",
    "        X_nonlnr['Platform_type_3_other(0)'][i]=int(0)\n",
    "        \n",
    "X_nonlnr.drop(['Platform Type_4', 'Platform Type_2', 'Platform Type_3','Temperature', 'Platform_type'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# investigate feature interactions and synergy\n",
    "\n",
    "X_nonlnr[['Personal or Business_Personal', 'Platform_type_3_other(0)']].head()\n",
    "\n",
    "X_nonlnr['Business_1_Personal_0']=np.nan\n",
    "for i in range(len(X_nonlnr['Business_1_Personal_0'])):\n",
    "    if X_nonlnr['Personal or Business_Personal'][i]==0:\n",
    "        X_nonlnr['Business_1_Personal_0'][i]=1\n",
    "    else:\n",
    "         X_nonlnr['Business_1_Personal_0'][i]=0\n",
    "\n",
    "#Interaction Variable (Business customer using platform 3 versus other customers)\n",
    "X_nonlnr['Business_Platform_3']= X_nonlnr['Business_1_Personal_0']* X_nonlnr['Platform_type_3_other(0)']\n",
    "X_nonlnr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model adjusted for non linearity\n",
    "#Splitting the data into training and testing datasets\n",
    "xnl_train, xnl_test, ynl_train, ynl_test=train_test_split(X_nonlnr,y, test_size=0.2,random_state=40)\n",
    "\n",
    "#Fitting the model\n",
    "nlm=LinearRegression()\n",
    "nlm.fit(xnl_train, ynl_train)\n",
    "ynl_pred=nlm.predict(xnl_test)\n",
    "\n",
    "#Model Perfomance Validation\n",
    "print( 'Rsquared :'  + str(r2_score(ynl_test, ynl_pred)))\n",
    "print('RMSE :' + str(np.sqrt(mean_squared_error(ynl_test, ynl_pred))))\n",
    "# Aim at having a RMSE of less than 780\n",
    "\n",
    "#The R2 and RMSE did not improve with feature enginearing, \n",
    "# That might be due to decreased number of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nonlnr[['Business_Platform_3','Business_1_Personal_0','Platform_type_3_other(0)']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scale=x_train[['No_Of_Orders', 'Age', 'Average_Rating', 'No_of_Ratings',\n",
    "       'Pickup - Day of Month', 'Distance (KM)', 'Temperature']]\n",
    "\n",
    "test_scale=x_test[['No_Of_Orders', 'Age', 'Average_Rating', 'No_of_Ratings',\n",
    "       'Pickup - Day of Month', 'Distance (KM)', 'Temperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_train=x_train[['Platform Type_2', 'Platform Type_3', 'Platform Type_4',\n",
    "       'Personal or Business_Personal', 'Pickup - Weekday (Mo = 1)_2',\n",
    "       'Pickup - Weekday (Mo = 1)_3', 'Pickup - Weekday (Mo = 1)_4',\n",
    "       'Pickup - Weekday (Mo = 1)_5', 'Pickup - Weekday (Mo = 1)_6',\n",
    "       'Pickup - Weekday (Mo = 1)_7', 'Pickup - Time(AM/PM)_PM']]\n",
    "\n",
    "dummies_test=x_test[['Platform Type_2', 'Platform Type_3', 'Platform Type_4',\n",
    "       'Personal or Business_Personal', 'Pickup - Weekday (Mo = 1)_2',\n",
    "       'Pickup - Weekday (Mo = 1)_3', 'Pickup - Weekday (Mo = 1)_4',\n",
    "       'Pickup - Weekday (Mo = 1)_5', 'Pickup - Weekday (Mo = 1)_6',\n",
    "       'Pickup - Weekday (Mo = 1)_7', 'Pickup - Time(AM/PM)_PM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x= StandardScaler()\n",
    "sc_y= StandardScaler()\n",
    "x_train_scaled=sc_x.fit_transform(train_scale)\n",
    "\n",
    "y_train_scaled=sc_y.fit_transform(y_train)\n",
    "x_test_scaled=sc_x.transform(test_scale)\n",
    "\n",
    "scaled_x_train=pd.DataFrame(x_train_scaled,columns= train_scale.columns,index=dummies_train.index)\n",
    "scaled_x_test=pd.DataFrame(x_test_scaled,columns= test_scale.columns,index=dummies_test.index)\n",
    "x_train_scaled_all=scaled_x_train.join(dummies_train)\n",
    "x_test_scaled_all=scaled_x_test.join(dummies_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_sc, x_test_sc, y_train_sc, y_test_sc=train_test_split(X_scaled,y_scaled, test_size=0.2,random_state=40)\n",
    "lm_sc=LinearRegression()\n",
    "lm_sc.fit(x_train_scaled_all, y_train_scaled)\n",
    "y_pred_lmsc=sc_y.inverse_transform(lm_sc.predict(x_test_scaled_all))\n",
    "\n",
    "#Model Perfomance Validation\n",
    "print( 'Rsquared :'  + str(r2_score(y_test, y_pred_lmsc)))\n",
    "print('RMSE :' + str(np.sqrt(mean_squared_error(y_test, y_pred_lmsc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# L1 and L2 Regularisation\n",
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "ridge.fit(x_train_scaled_all, y_train_scaled)\n",
    "ypred_ridge =sc_y.inverse_transform (ridge.predict(x_test_scaled_all))\n",
    "\n",
    "print('Ridge MSE')\n",
    "\n",
    "ridge_test=np.sqrt(mean_squared_error(y_test, ypred_ridge))\n",
    "ridge_train=np.sqrt(mean_squared_error(y_train, sc_y.inverse_transform (ridge.predict(x_train_scaled_all))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# create LASSO model object, setting alpha to 0.01\n",
    "lasso = Lasso(alpha=0.01)\n",
    "# train the LASSO model\n",
    "lasso.fit(x_train_scaled_all, y_train_scaled)\n",
    "\n",
    "y_pred_lasso=sc_y.inverse_transform (lasso.predict(x_test_scaled_all))\n",
    "lasso_test=np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "lasso_train=np.sqrt(mean_squared_error(y_train, sc_y.inverse_transform (lasso.predict(x_train_scaled_all))))\n",
    "print('R2:', r2_score(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pd.DataFrame(lasso.coef_, X_dummies.columns, columns=['Coefficient'])\n",
    "coeff\n",
    "\n",
    "#From Lasso regression the following variables caan be dropped as their coefficients shrinked to zero\n",
    "#[Age,Pickup - Day of Month,Temperature,Platform Type_2,Platform Type_3,Platform Type_4, Personal or Business_Personal,\n",
    "#Pickup - Weekday (Mo = 1)_5,Pickup - Weekday (Mo = 1)_6,Pickup - Weekday (Mo = 1)_7,\n",
    "#Pickup - Weekday (Mo = 1)_2,Pickup - Weekday (Mo = 1)_3,Pickup - Weekday (Mo = 1)_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models with outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# minimal data preprocessing (just enough to build base model)\n",
    "#Removing Outliers\n",
    "df_outliers_re= X_dummies.copy()\n",
    "df_outliers_re['Time from Pickup to Arrival']=y\n",
    "\n",
    "indexNames = df_outliers_re[(df_outliers_re['Time from Pickup to Arrival'] <30) & (df_outliers_re['Distance (KM)']>1)].index\n",
    "indexNames2 = df_outliers_re[df_outliers_re['Time from Pickup to Arrival'] >4000].index\n",
    "\n",
    "df_outliers_re.drop(indexNames, inplace=True)\n",
    "df_outliers_re.drop(indexNames2, inplace=True)\n",
    "# Target and Feature variables without outliers\n",
    "X2=df_outliers_re.drop('Time from Pickup to Arrival', axis=1)\n",
    "y2=df_outliers_re['Time from Pickup to Arrival']\n",
    "y2=np.array(y2).reshape(len(y2),1)\n",
    "\n",
    "#Removing outliers in the non linear model\n",
    "df2_outliers_re= X_nonlnr.copy()\n",
    "df2_outliers_re['Time from Pickup to Arrival']=y\n",
    "df2_outliers_re.drop(indexNames, inplace=True)\n",
    "df2_outliers_re.drop(indexNames2, inplace=True)\n",
    "\n",
    "# Target and Feature variables without outliers\n",
    "X3=df2_outliers_re.drop('Time from Pickup to Arrival', axis=1)\n",
    "y3=df2_outliers_re['Time from Pickup to Arrival']\n",
    "y3=np.array(y2).reshape(len(y3),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit Linear model without outliers\n",
    "#Splitting the data into training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train2, x_test2, y_train2, y_test2=train_test_split(X2,y2, test_size=0.2,random_state=40)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm_no=LinearRegression()\n",
    "lm_no.fit(x_train2, y_train2)\n",
    "y_pred2=lm_no.predict(x_test2)\n",
    "\n",
    "#Model Perfomance Validation\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print( 'Rsquared :'  + str(r2_score(y_test2, y_pred2)))\n",
    "\n",
    "lm_nooutlier_train=np.sqrt(mean_squared_error(y_train2, lm_no.predict(x_train2)))\n",
    "lm_nooutlier_test=np.sqrt(mean_squared_error(y_test2, y_pred2))\n",
    "# Aim at having a RMSE of less than 780\n",
    "print(lm_nooutlier_train)\n",
    "print(lm_nooutlier_test)\n",
    "#and cross validate perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit non Linear model without outliers\n",
    "#Splitting the data into training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train3, x_test3, y_train3, y_test3=train_test_split(X3,y3, test_size=0.2,random_state=40)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "nlm_no=LinearRegression()\n",
    "nlm_no.fit(x_train2, y_train3)\n",
    "y_pred3=nlm_no.predict(x_test3)\n",
    "\n",
    "#Model Perfomance Validation\n",
    "print( 'Rsquared :'  + str(r2_score(y_test3, y_pred3)))\n",
    "np.sqrt(mean_squared_error(y_test3, y_pred3))\n",
    "\n",
    "#Even after removing outliers this model with transformed features performs worse that the linear model, after removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalling the features of the dataset without outliers\n",
    "train2_scale=x_train2[['No_Of_Orders', 'Age', 'Average_Rating', 'No_of_Ratings',\n",
    "       'Pickup - Day of Month', 'Distance (KM)', 'Temperature']]\n",
    "\n",
    "test2_scale=x_test2[['No_Of_Orders', 'Age', 'Average_Rating', 'No_of_Ratings',\n",
    "       'Pickup - Day of Month', 'Distance (KM)', 'Temperature']]\n",
    "\n",
    "dummies_train2=x_train2[['Platform Type_2', 'Platform Type_3', 'Platform Type_4',\n",
    "       'Personal or Business_Personal', 'Pickup - Weekday (Mo = 1)_2',\n",
    "       'Pickup - Weekday (Mo = 1)_3', 'Pickup - Weekday (Mo = 1)_4',\n",
    "       'Pickup - Weekday (Mo = 1)_5', 'Pickup - Weekday (Mo = 1)_6',\n",
    "       'Pickup - Weekday (Mo = 1)_7', 'Pickup - Time(AM/PM)_PM']]\n",
    "\n",
    "dummies_test2=x_test2[['Platform Type_2', 'Platform Type_3', 'Platform Type_4',\n",
    "       'Personal or Business_Personal', 'Pickup - Weekday (Mo = 1)_2',\n",
    "       'Pickup - Weekday (Mo = 1)_3', 'Pickup - Weekday (Mo = 1)_4',\n",
    "       'Pickup - Weekday (Mo = 1)_5', 'Pickup - Weekday (Mo = 1)_6',\n",
    "       'Pickup - Weekday (Mo = 1)_7', 'Pickup - Time(AM/PM)_PM']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x2= StandardScaler()\n",
    "sc_y2= StandardScaler()\n",
    "x_train_scaled2=sc_x2.fit_transform(train2_scale)\n",
    "\n",
    "y_train_scaled2=sc_y2.fit_transform(y_train2)\n",
    "x_test_scaled2=sc_x2.transform(test2_scale)\n",
    "\n",
    "scaled_x2_train=pd.DataFrame(x_train_scaled2,columns= train2_scale.columns,index=dummies_train2.index)\n",
    "scaled_x2_test=pd.DataFrame(x_test_scaled2,columns= test2_scale.columns,index=dummies_test2.index)\n",
    "x2_train_scaled_all=scaled_x2_train.join(dummies_train2)\n",
    "x2_test_scaled_all=scaled_x2_test.join(dummies_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit Linear model without outliers and scaled features \n",
    "lmsc_no=LinearRegression()\n",
    "lmsc_no.fit(x2_train_scaled_all, y_train_scaled2)\n",
    "ysc_pred_no=sc_y2.inverse_transform(lmsc_no.predict(x2_test_scaled_all))\n",
    "\n",
    "#Model Perfomance Validation\n",
    "print( 'Rsquared :'  + str(r2_score(y_test2, ysc_pred_no)))\n",
    "\n",
    "lmscaled_no_outlier_train=round(np.sqrt(mean_squared_error(y_train2, sc_y2.inverse_transform(lmsc_no.predict(x2_train_scaled_all)))),0)\n",
    "lmscaled_no_outlier_test=round(np.sqrt(mean_squared_error(y_test2, ysc_pred_no)),0)\n",
    "\n",
    "print(lmscaled_no_outlier_train)\n",
    "print(lmscaled_no_outlier_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_no = Ridge()\n",
    "ridge_no.fit(x2_train_scaled_all, y_train_scaled2)\n",
    "y_ridge_no =sc_y2.inverse_transform (ridge_no.predict(x2_test_scaled_all))\n",
    "\n",
    "print('Ridge MSE')\n",
    "ridge_no_outlier_train=round(np.sqrt(mean_squared_error(y_train2, sc_y2.inverse_transform (ridge_no.predict(x2_train_scaled_all)))),0)\n",
    "ridge_no_outlier_test= round(np.sqrt(mean_squared_error(y_test2, y_ridge_no)),0)\n",
    "\n",
    "print(ridge_no_outlier_train)\n",
    "print(ridge_no_outlier_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_no = Lasso()\n",
    "lasso_no.fit(x2_train_scaled_all, y_train_scaled2)\n",
    "y_lasso_no =sc_y2.inverse_transform (ridge_no.predict(x2_test_scaled_all))\n",
    "\n",
    "print('Lasso MSE')\n",
    "lasso_nooutlier_train =np.sqrt( mean_squared_error(y_train2, sc_y2.inverse_transform (lasso_no.predict(x2_train_scaled_all))))\n",
    "lasso_nooutlier_test  =np.sqrt(mean_squared_error(y_test2, y_lasso_no))\n",
    "\n",
    "print(lasso_nooutlier_train )\n",
    "print(lasso_nooutlier_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train_scaled_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Selection \n",
    "* backward eliminations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers_re.corr()\n",
    "from statsmodels.graphics.correlation import plot_corr\n",
    "\n",
    "fig = plt.figure(figsize=(15,15));\n",
    "ax = fig.add_subplot(111);\n",
    "plot_corr(df_outliers_re.corr(), xnames = df_outliers_re.corr().columns, ax = ax);\n",
    "\n",
    "#Age and number of orders are highly correlated\n",
    "# Number of orders and number oratings are also correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations between predictor variables and the response variable\n",
    "corrs = df_outliers_re.corr()['Time from Pickup to Arrival'].sort_values(ascending=False)\n",
    "corrs\n",
    "\n",
    "# Nomber of ratings is highly correlated with time from pick up to arrrival,\n",
    "# therefore number of orders can be removed since is is correlated with both age and number of ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Build a dictionary of correlation coefficients and p-values\n",
    "dict_cp = {}\n",
    "\n",
    "column_titles = [col for col in corrs.index if col!= 'Time from Pickupt to Arrival']\n",
    "for col in column_titles:\n",
    "    p_val = round(pearsonr(df_outliers_re[col], df_outliers_re['Time from Pickup to Arrival'])[1],6)\n",
    "    dict_cp[col] = {'Correlation_Coefficient':corrs[col],\n",
    "                    'P_Value':p_val}\n",
    "    \n",
    "df_cp = pd.DataFrame(dict_cp).T\n",
    "df_cp_sorted = df_cp.sort_values('P_Value')\n",
    "df_cp_sorted[df_cp_sorted['P_Value']<0.1]\n",
    "\n",
    "#Age,number of orders and number of ratings have high p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dependent variable remains the same:\n",
    "y_data =df_outliers_re['Time from Pickup to Arrival']  # y_name = 'Loan_Size'\n",
    "\n",
    "# Model building - Independent Variable (IV) DataFrame\n",
    "X_names = list(df_cp[df_cp['P_Value'] < 0.05].index)\n",
    "X_data = df_outliers_re[X_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the correlation matrix\n",
    "corr = X_data.corr()\n",
    "\n",
    "# Find rows and columnd where correlation coefficients > 0.9 or <-0.9\n",
    "corr[np.abs(corr) > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, we create the correlation matrix\n",
    "# and find rows and columnd where correlation coefficients > 0.9 or <-0.9\n",
    "corr = X_data.corr()\n",
    "r, c = np.where(np.abs(corr) > 0.9)\n",
    "\n",
    "# We are only interested in the off diagonal entries:\n",
    "off_diagonal = np.where(r != c)\n",
    "\n",
    "# Show the correlation matrix rows and columns where we have highly correlated off diagonal entries:\n",
    "corr.iloc[r[off_diagonal], c[off_diagonal]]\n",
    "\n",
    "# NO correlation of above 0.9 oir less -0.9. all the variables are kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers_re.columns=['No_Of_Orders', 'Age', 'Average_Rating', 'No_of_Ratings',\n",
    "       'Pickup_Day_of_Month', 'Distance_KM', 'Temperature',\n",
    "       'Platform_Type_2', 'Platform_Type_3', 'Platform_Type_4',\n",
    "       'Personal_or_Business_Personal', 'Pickup_Weekday_2',\n",
    "       'Pickup_Weekday_3', 'Pickup_Weekday_4',\n",
    "       'Pickup_Weekday_5', 'Pickup_Weekday_6',\n",
    "       'Pickup_Weekday_7', 'Pickup_Time_AM_0_PM_1',\n",
    "       'Time_from_Pickup_to_Arrival']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a new subset of our potential independent variables\n",
    "X_corr_names = df_outliers_re.drop('Time_from_Pickup_to_Arrival', axis=1).columns\n",
    "y_name='Time_from_Pickup_to_Arrival'\n",
    "\n",
    "# Create our new OLS formula based-upon our smaller subset\n",
    "formula_str = y_name+' ~ '+' + '.join(X_corr_names);\n",
    "print('Formula:\\n\\t{}'.format(formula_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit the OLS model using the model dataframe\n",
    "from statsmodels.formula.api import ols\n",
    "model=ols(formula=formula_str, data=df_outliers_re)\n",
    "fitted = model.fit()\n",
    "\n",
    "# Display the fitted summary\n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the above model, \n",
    "#Number of orders, teperature and pickup day of the month are not significant, will use backward selection to remove ach of them\n",
    "# removing temperature\n",
    "X_corr_names = df_outliers_re.drop(['Time_from_Pickup_to_Arrival', 'Temperature'], axis=1).columns\n",
    "\n",
    "# Create our new OLS formula based-upon our smaller subset\n",
    "formula_str = y_name+' ~ '+' + '.join(X_corr_names);\n",
    "# Fit the OLS model using the model dataframe\n",
    "from statsmodels.formula.api import ols\n",
    "model1=ols(formula=formula_str, data=df_outliers_re)\n",
    "fitted = model1.fit()\n",
    "\n",
    "# Display the fitted summary\n",
    "print(fitted.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the above model, \n",
    "#Number of orders, teperature and pickup day of the month are not significant, will use backward elimination to remove ach of them\n",
    "# removing temperature\n",
    "X_corr_names = df_outliers_re.drop(['Time_from_Pickup_to_Arrival', 'Temperature','Pickup_Day_of_Month' ], axis=1).columns\n",
    "\n",
    "# Create our new OLS formula based-upon our smaller subset\n",
    "formula_str = y_name+' ~ '+' + '.join(X_corr_names);\n",
    "# Fit the OLS model using the model dataframe\n",
    "from statsmodels.formula.api import ols\n",
    "model2=ols(formula=formula_str, data=df_outliers_re)\n",
    "fitted = model2.fit()\n",
    "\n",
    "# Display the fitted summary\n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the above model, \n",
    "#Number of orders, teperature and pickup day of the month are not significant, will use backward elimination to remove ach of them\n",
    "# removing temperature\n",
    "X_corr_names = df_outliers_re.drop(['Time_from_Pickup_to_Arrival', 'Temperature','Pickup_Day_of_Month', 'No_of_Ratings' ],\n",
    "                                   axis=1).columns\n",
    "\n",
    "# Create our new OLS formula based-upon our smaller subset\n",
    "formula_str = y_name+' ~ '+' + '.join(X_corr_names);\n",
    "# Fit the OLS model using the model dataframe\n",
    "from statsmodels.formula.api import ols\n",
    "model2=ols(formula=formula_str, data=df_outliers_re)\n",
    "fitted = model2.fit()\n",
    "\n",
    "# Display the fitted summary\n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the above model, \n",
    "#Number of orders, teperature and pickup day of the month are not significant, will use backward elimination to remove ach of them\n",
    "# removing temperature\n",
    "X_corr_names = df_outliers_re.drop(['Time_from_Pickup_to_Arrival', 'Temperature','Pickup_Day_of_Month', 'No_of_Ratings',\n",
    "                                   'Platform_Type_2','Platform_Type_3','Platform_Type_4'],\n",
    "                                   axis=1).columns\n",
    "\n",
    "# Create our new OLS formula based-upon our smaller subset\n",
    "formula_str = y_name+' ~ '+' + '.join(X_corr_names);\n",
    "# Fit the OLS model using the model dataframe\n",
    "from statsmodels.formula.api import ols\n",
    "model2=ols(formula=formula_str, data=df_outliers_re)\n",
    "fitted = model2.fit()\n",
    "\n",
    "# Display the fitted summary\n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After removing number of ratings, number of orders became significant\n",
    "# Above is the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use SKLearn to train and run the final model\n",
    "\n",
    "X_final= df_outliers_re.drop(['Time_from_Pickup_to_Arrival', 'Temperature','Pickup_Day_of_Month', 'No_of_Ratings',\n",
    "                                   'Platform_Type_2','Platform_Type_3','Platform_Type_4' ],\n",
    "                                   axis=1)\n",
    "y_final=df_outliers_re['Time_from_Pickup_to_Arrival']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_trainf, x_testf, y_trainf, y_testf=train_test_split(X_final,y_final, test_size=0.2,random_state=40)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "flm_no=LinearRegression()\n",
    "flm_no.fit(x_trainf, y_trainf)\n",
    "y_predf=flm_no.predict(x_testf)\n",
    "\n",
    "#Model Perfomance Validation\n",
    "print( 'Rsquared :'  + str(r2_score(y_testf, y_predf)))\n",
    "\n",
    "flm_train=np.sqrt(mean_squared_error(y_trainf, flm_no.predict(x_trainf)))\n",
    "flm_test= np.sqrt(mean_squared_error(y_testf, y_predf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembled Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Random forests and feature importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 150, random_state = 0)\n",
    "regressor.fit(x_train, y_train)\n",
    "yrd_pred = regressor.predict(x_test)\n",
    "r2_score(y_test, yrd_pred)\n",
    "rf_test= np.sqrt( mean_squared_error(y_test, yrd_pred))\n",
    "rf_train= np.sqrt( mean_squared_error(y_train, regressor.predict(x_train)))\n",
    "\n",
    "rf_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Random forests without outliers and feature importance\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 150, random_state = 0)\n",
    "rf.fit(x_train2, y_train2)\n",
    "yrd_no_pred = rf.predict(x_test2)\n",
    "r2_score(y_test2, yrd_no_pred)\n",
    "rf_nooutlier_train=np.sqrt( mean_squared_error(y_train2,rf.predict(x_train2)))\n",
    "rf_nooutlier_test=np.sqrt( mean_squared_error(y_test2,yrd_no_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fit multiple models and do hyper-parameter tuning\n",
    "#withoutliers\n",
    "\n",
    "#Ploting RMSE without ouliers\n",
    "\n",
    "p=[lm_test, lm_test]\n",
    "m=[ridge_train,ridge_test]\n",
    "v=[lasso_train,lasso_train]\n",
    "r=[rf_train, rf_test]\n",
    "#rf_nooutlier\n",
    "x=['train', 'test']\n",
    "#plt.plot(x,y)\n",
    "plt.plot(x,p, label='OLS', )\n",
    "plt.plot(x,m, label='Ridge')\n",
    "plt.plot(x,v, label='Lasso')\n",
    "plt.plot(x,r, label='Random forest')\n",
    "\n",
    "plt.xlabel('training versus testing samples')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "plt.title('RMSE comparison')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OLS is performing better than Lasso and Random forest\n",
    "* Random forest is overffiting the training data and can not generalise to unseen data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fit multiple models and do hyper-parameter tuning\n",
    "#withoutliers\n",
    "\n",
    "#Ploting RMSE without ouliers\n",
    "\n",
    "p=[flm_train,flm_test]\n",
    "m=[ridge_no_outlier_train,ridge_no_outlier_test]\n",
    "v=[lasso_nooutlier_train,lasso_nooutlier_test]\n",
    "r=[rf_nooutlier_train, rf_nooutlier_test]\n",
    "#rf_nooutlier\n",
    "x=['train', 'test']\n",
    "#plt.plot(x,y)\n",
    "plt.plot(x,p, label='OLS', )\n",
    "plt.plot(x,m, label='Ridge')\n",
    "plt.plot(x,v, label='Lasso')\n",
    "plt.plot(x,r, label='Random forest')\n",
    "\n",
    "plt.xlabel('training versus testing samples')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "plt.title('RMSE comparison without outliers')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After outliers were removed, all models perfomed better\n",
    "* OLS is perfoming exactly the same as Ridge model\n",
    "* OLS has the best fit. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 403.31234,
   "position": {
    "height": "425.958px",
    "left": "7.33333px",
    "right": "20px",
    "top": "404px",
    "width": "349.646px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
